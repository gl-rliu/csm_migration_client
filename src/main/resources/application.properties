spring.application.name=avro

# Confluent Cloud Schema Registry
spring.kafka.properties.basic.auth.credentials.source=USER_INFO
spring.kafka.properties.basic.auth.user.info=UJMM2AMJJBCWK7IR:BokeGHZTpHSz1r/Ix7qy51l8XNIsh82raDta+j4GYjms0EDzOUAb1sXpCjJpB/a5
spring.kafka.properties.schema.registry.url=https://psrc-q2n1d.westus2.azure.confluent.cloud

# Required connection configs for Kafka producer, consumer, and admin
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.bootstrap-servers=pkc-56d1g.eastus.azure.confluent.cloud:9092
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='FUUUHCFLITMUL5TR' password='RvpHNJnyVgK2j4Z7Bd3qCnit193GbdMQVJfQqwbgXO8PUmSYWCOkCbCN4yy4xpuh';
spring.kafka.properties.security.protocol=SASL_SSL

# Best practice for higher availability in Apache Kafka clients prior to 3.0
spring.kafka.properties.session.timeout.ms=45000

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.KafkaAvroSerializer

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer

spring.kafka.properties.auto.register.schemas=false
spring.kafka.properties.use.latest.version=true

spring.devtools.enabled=true
server.port=8089

socket.host=0.0.0.0
socket.port=3001

debug.enabled=true
topic.name=ET1-BM1-ET8

# These properties are required for encryption/decryption if you're not sharing the key with Confluent.
# rule.executors=aws
# rule.executors.aws.class=io.confluent.kafka.schemaregistry.encryption.aws.AwsFieldEncryptionExecutor
# rule.executors._default_.param.access.key.id=<YOUR_AWS_ACCESS_KEY_ID>
# rule.executors._default_.param.secret.access.key=<YOUR_AWS_SECRET_ACCESS_KEY>
